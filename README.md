# German Credit Risk Scorecard with Kedro ğŸš€

Este Ã© um projeto de carÃ¡ter tÃ©cnico e fundamental, desenvolvido com o objetivo central de explorar e demonstrar as capacidades do framework Kedro e a aplicaÃ§Ã£o de princÃ­pios de MLOps. O foco aqui nÃ£o Ã© apenas a performance preditiva, mas a estruturaÃ§Ã£o de um pipeline de dados robusto, modular e persistente.


![kedro viz](https://github.com/vilquer/credit-risk-kedro/blob/0b9ceabdd429911285fb647b92480337defd7170/img/viz.png)

## ğŸ“‹ VisÃ£o Geral do Pipeline

O projeto foi estruturado utilizando o framework **Kedro**, dividindo a lÃ³gica em camadas de dados (Data Engineering e Data Science):

1. **Raw**: Dados brutos da UCI Machine Learning Repository.
    
2. **Intermediate**: Limpeza e mapeamento de domÃ­nios (conversÃ£o de cÃ³digos tÃ©cnicos para labels de negÃ³cio).
    
3. **Primary**: SeleÃ§Ã£o de atributos baseada em **Information Value (IV)**.
    
4. **Model Input**: PreparaÃ§Ã£o numÃ©rica via One-Hot Encoding (Dummies).
    
5. **Models**: Treinamento de Random Forest e persistÃªncia do modelo (Pickle).
    
6. **Reporting**: AvaliaÃ§Ã£o de performance focada em mÃ©tricas de risco (**Gini** e **AUC**).

   ![dados](https://github.com/vilquer/credit-risk-kedro/blob/0b9ceabdd429911285fb647b92480337defd7170/img/data.png)

---

## ğŸ› ï¸ Tecnologias e Metodologias

- **Linguagem:** Python 3.10
    
- **Framework de Pipeline:** [Kedro](https://kedro.org/)
    
- **EstatÃ­stica de Risco:** Information Value (IV) & Weight of Evidence (WoE)
    
- **Machine Learning:** Scikit-Learn (Random Forest)
    
- **PersistÃªncia:** Apache Parquet (eficiÃªncia de storage e tipos)
    
- **GestÃ£o:** PrincÃ­pios de **Data Driven Scrum (DDS)**
    

---

## ğŸ“ˆ Resultados de Performance

O modelo Ã© avaliado automaticamente, gerando um relatÃ³rio em `data/08_reporting/performance_metric.json`.

|**MÃ©trica**|**Valor Obtido**|
|---|---|
|**AUC**|0.7X|
|**GINI**|0.4X|

> **Nota:** O Gini obtido Ã© condizente com benchmarks de mercado para o dataset German Credit, demonstrando um poder discriminatÃ³rio sÃ³lido entre bons e maus pagadores.

---

## ğŸš€ Como Executar

1. **Instalar dependÃªncias:**
    
    Bash
    
    ```
    pip install -r src/requirements.txt
    ```
    
2. **Executar o pipeline completo:**
    
    Bash
    
    ```
    kedro run
    ```
    
3. **Visualizar o grafo do projeto:**
    
    Bash
    
    ```
    kedro viz
    ```
    

---

## ğŸ§  DecisÃµes de Arquitetura (Tech Lead Insights)

- **Filtro de IV:** Implementamos uma seleÃ§Ã£o automÃ¡tica que remove variÃ¡veis com IV < 0.02, garantindo que o modelo foque apenas em preditores com poder estatÃ­stico.
    
- **PersistÃªncia em Parquet:** Escolhido em detrimento do CSV para garantir que os tipos de dados (especialmente apÃ³s o binning) fossem preservados entre os nÃ³s.
    
- **Mapeamento de NegÃ³cio:** Priorizamos a legibilidade dos dados na camada `intermediate` para facilitar Sprints de revisÃ£o com stakeholders nÃ£o tÃ©cnicos.
    

---

## ğŸ‘¨â€ğŸ’» Autor

 [<img src="https://avatars.githubusercontent.com/u/52363892?v=4" width=115><br><sub><b>Vilquer de Oliveira</b></sub>](https://github.com/vilquer) 


_Data Scientist | Tech Lead | Especialista em IA e Engenharia de Software_
